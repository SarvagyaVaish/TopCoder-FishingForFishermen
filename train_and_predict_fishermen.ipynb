{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import urllib\n",
    "\n",
    "train_file = 'data/clean_training_data.csv'\n",
    "test_file = 'data/clean_testing_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "COLUMNS = ['TIMESTAMP','FISHING_STATUS','CHECKSUM','slot_increment','sync_state','true_heading','sog','slots_to_allocate','rot','nav_status','repeat_indicator','raim','id','spare','keep_flag','cog','timestamp','y','x','position_accuracy','rot_over_range','mmsi','special_manoeuvre','slot_timeout','slot_offset','slot_number','received_stations','utc_spare','utc_min','utc_hour','unit_flag','spare2','mode_flag','m22_flag','commstate_cs_fill','commstate_flag','display_flag','dsc_flag','band_flag','gnss','fix_type','type_and_cargo','spare3','dim_d','assigned_mode','dim_b','dim_c','dim_a','name','dte']\n",
    "df_train = pd.read_csv(train_file, names=COLUMNS, skipinitialspace=True, skiprows=1)\n",
    "\n",
    "COLUMNS_TEST = ['TIMESTAMP','CHECKSUM','slot_increment','sync_state','true_heading','sog','slots_to_allocate','rot','nav_status','repeat_indicator','raim','id','spare','keep_flag','cog','timestamp','y','x','position_accuracy','rot_over_range','mmsi','special_manoeuvre','slot_timeout','slot_offset','slot_number','received_stations','utc_spare','utc_min','utc_hour','unit_flag','spare2','mode_flag','m22_flag','commstate_cs_fill','commstate_flag','display_flag','dsc_flag','band_flag','gnss','fix_type','type_and_cargo','spare3','dim_d','assigned_mode','dim_b','dim_c','dim_a','name','dte']\n",
    "df_test = pd.read_csv(test_file, names=COLUMNS_TEST, skipinitialspace=True, skiprows=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LABEL_COLUMN = \"label\"\n",
    "def status_as_num(x):\n",
    "    if x == 'Unknown':\n",
    "        return 0\n",
    "    if x == 'Fishing':\n",
    "        return 1\n",
    "    if x == \"Not_Fishing\":\n",
    "        return 0\n",
    "\n",
    "def status_unknown(x):\n",
    "    return 0\n",
    "\n",
    "df_train[LABEL_COLUMN] = (df_train[\"FISHING_STATUS\"].apply(status_as_num)).astype(int)\n",
    "df_test[LABEL_COLUMN] = (df_test[\"TIMESTAMP\"].apply(status_unknown)).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CATEGORICAL_COLUMNS = []\n",
    "CONTINUOUS_COLUMNS = [\"sog\", \"cog\", \"x\", \"y\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def train_fn():\n",
    "    df = df_train\n",
    "    # Creates a dictionary mapping from each continuous feature column name (k) to\n",
    "    # the values of that column stored in a constant Tensor.\n",
    "    continuous_cols = {k: tf.constant(df[k].values) for k in CONTINUOUS_COLUMNS}\n",
    "    \n",
    "    # Creates a dictionary mapping from each categorical feature column name (k)\n",
    "    # to the values of that column stored in a tf.SparseTensor.\n",
    "    categorical_cols = {k: tf.SparseTensor(\n",
    "        indices=[[i, 0] for i in range(df[k].size)],\n",
    "        values=df[k].values,\n",
    "        shape=[df[k].size, 1]) for k in CATEGORICAL_COLUMNS}\n",
    "\n",
    "    # Merges the two dictionaries into one.\n",
    "    feature_cols = dict(continuous_cols.items() + categorical_cols.items())\n",
    "\n",
    "    # Converts the label column into a constant Tensor.\n",
    "    label = tf.constant(df[LABEL_COLUMN].values)\n",
    "    \n",
    "    # Returns the feature columns and the label.\n",
    "    return feature_cols, label\n",
    "\n",
    "\n",
    "def predict_fn():\n",
    "    df = df_test\n",
    "    \n",
    "    # Creates a dictionary mapping from each continuous feature column name (k) to\n",
    "    # the values of that column stored in a constant Tensor.\n",
    "    continuous_cols = {k: tf.constant(df[k].values) for k in CONTINUOUS_COLUMNS}\n",
    "    \n",
    "    # Creates a dictionary mapping from each categorical feature column name (k)\n",
    "    # to the values of that column stored in a tf.SparseTensor.\n",
    "    categorical_cols = {k: tf.SparseTensor(\n",
    "        indices=[[i, 0] for i in range(df[k].size)],\n",
    "        values=df[k].values,\n",
    "        shape=[df[k].size, 1]) for k in CATEGORICAL_COLUMNS}\n",
    "\n",
    "    # Merges the two dictionaries into one.\n",
    "    feature_cols = dict(continuous_cols.items() + categorical_cols.items())\n",
    "\n",
    "    # Converts the label column into a constant Tensor.\n",
    "    label = tf.constant(df[LABEL_COLUMN].values)\n",
    "    \n",
    "    # Returns the feature columns and the label.\n",
    "    return feature_cols, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_sog = tf.contrib.layers.real_valued_column(\"sog\")\n",
    "feature_cog = tf.contrib.layers.real_valued_column(\"cog\")\n",
    "feature_x = tf.contrib.layers.real_valued_column(\"x\")\n",
    "feature_y = tf.contrib.layers.real_valued_column(\"y\")\n",
    "\n",
    "# feature_raim = tf.contrib.layers.sparse_column_with_hash_bucket(\"raim\", hash_bucket_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using default config.\n"
     ]
    }
   ],
   "source": [
    "model_dir = tempfile.mkdtemp()\n",
    "m = tf.contrib.learn.LinearClassifier(\n",
    "    feature_columns=[feature_sog, feature_cog, feature_x, feature_y],\n",
    "    model_dir=model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Setting feature info to {'y': TensorSignature(dtype=tf.float64, shape=TensorShape([Dimension(142533)]), is_sparse=False), 'x': TensorSignature(dtype=tf.float64, shape=TensorShape([Dimension(142533)]), is_sparse=False), 'cog': TensorSignature(dtype=tf.float64, shape=TensorShape([Dimension(142533)]), is_sparse=False), 'sog': TensorSignature(dtype=tf.float64, shape=TensorShape([Dimension(142533)]), is_sparse=False)}\n",
      "WARNING:tensorflow:Setting targets info to TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(142533)]), is_sparse=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearClassifier()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(input_fn=train_fn, steps=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[  2.72093490e-02,   9.72790599e-01],\n",
      "       [  9.39468503e-01,   6.05315641e-02],\n",
      "       [  1.00000000e+00,   2.03838321e-10],\n",
      "       ..., \n",
      "       [  9.97358859e-01,   2.64117937e-03],\n",
      "       [  1.00000000e+00,   2.51744439e-08],\n",
      "       [  2.76224494e-01,   7.23775506e-01]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "prediction = m.predict_proba(input_fn=predict_fn)\n",
    "pp.pprint(prediction)\n",
    "\n",
    "outputFile = open('data/predictions_c.txt', 'wb')\n",
    "for p in prediction:\n",
    "    outputFile.write(str(float(p[1])) + '\\n')\n",
    "outputFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([1, 0, 0, ..., 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "prediction = m.predict(input_fn=predict_fn)\n",
    "pp.pprint(prediction)\n",
    "\n",
    "outputFile = open('data/predictions_d.txt', 'wb')\n",
    "for p in prediction:\n",
    "    outputFile.write(str(float(p)) + '\\n')\n",
    "outputFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
